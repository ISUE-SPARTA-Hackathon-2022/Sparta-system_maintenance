{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Establishment\n",
    "- Virtual Environment (venv.txt)\n",
    "\n",
    "# Arrange the data to be used\n",
    "- create resources folder inside Machine_Learning\n",
    "- create Actual folder inside resources\n",
    "- create 2 folder namely test and train in the Actual folder\n",
    "- each of the 2 folder should have same set of folder which is (exportable, marketable, reject)\n",
    ">> Note: the train and test folder should have excatly same named, count and syntax of named folder\n",
    ">> Note: folder name should note have space if you want to change it\n",
    ">> folder will serve as the name of the class\n",
    "\n",
    "# Use the code below to create, run, test and save the model\n",
    "\n",
    "# If you want to check the data/graph of learning of the model you can use the tensorboard_command.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "\n",
    "## Tensorflow one of the library that can build ML\n",
    "import tensorflow as tf\n",
    "## helper library which is tailored to code less\n",
    "import helper as helper\n",
    "## this will create a web ready model to be used for website\n",
    "import tensorflowjs as tfjs\n",
    "## use for re-initializing the custom library\n",
    "import sys\n",
    "\n",
    "## this object declaration of the class inside the helper library\n",
    "_helper = helper.helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## every library declared here is to lessen the code sequence for the preparation of data, ML building and testing\n",
    "from keras import Sequential, Model\n",
    "from keras.utils import plot_model as pltmdl\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Input\n",
    "from keras.layers import GlobalAveragePooling2D, RandomFlip, RandomCrop\n",
    "from keras.layers import RandomRotation, RandomZoom, RandomHeight, RandomWidth\n",
    "from keras.layers import Rescaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use to reload the custom library when there is change in the library\n",
    "from importlib import reload\n",
    "reload(sys.modules[\"helper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: \n",
      "Found 90 files belonging to 3 classes.\n",
      "Train Data: \n",
      "Found 920 files belonging to 3 classes.\n",
      "Class Names: ['exportable', 'marketable', 'reject']\n"
     ]
    }
   ],
   "source": [
    "### The try here catches any error that will occur and report back the error and also with notification integrated\n",
    "try:\n",
    "  ## train_test_dir_setter is used to set the data, so called data preparations to be used by ML \n",
    "    ## the function can inspected inside the helper.py\n",
    "  ## train_test_dir_setter, requires\n",
    "    ## 1. test_var, train_var, class_var if you have the folder test and train only\n",
    "    ## 2. test_var, train_var, eval_var, class_var if you have the folder test, train and eval\n",
    "  ## for inputs; Requirements will be the directory of the file to be used. and also it has other more inputs just hover over train_test_dir_setter\n",
    "  ## if the code is success it will display below the count of files found for test, train, eval and also the class names\n",
    "  test_data, train_data, CLASS_NAMES = _helper.data_preparations.train_test_dir_setter(\"./resources/Actual/\",IMG_SIZE = (500, 500),CLASS_MODE = \"categorical\")\n",
    "except Exception as e:\n",
    "  print(f\"Error: {e}\")\n",
    "  _helper.notifications.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  ## the checkpoint_callback will produce call back function for the ML to store the best state it was when trained\n",
    "  ## this produce two variable the checkpoint function and the checkpoint saving the checkpoint directory\n",
    "  ## this require where to save (dir), file name (name)\n",
    "  ## the val_loss inside and the other true are not required and for further information just hover over checkpoint_callback\n",
    "  checkpoint, ckpt_dir = _helper.callbacks.checkpoint_callback(\n",
    "    \"./saved_files/finalUlit\",\n",
    "    \"final\",\n",
    "    \"val_loss\",\n",
    "    True,\n",
    "    True\n",
    "  )\n",
    "except Exception as e:\n",
    "  print(f\"Error: {e}\")\n",
    "  _helper.notifications.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard Log Files to: ./log/finalUlit/Final_model/2022_10_31__19_07_log\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 250s 8s/step - loss: 1.1357 - categorical_accuracy: 0.4272 - precision: 0.3475 - val_loss: 1.0970 - val_categorical_accuracy: 0.3444 - val_precision: 0.4000\n",
      "Epoch 2/20\n",
      " 9/29 [========>.....................] - ETA: 2:26 - loss: 1.0189 - categorical_accuracy: 0.5174 - precision: 0.5484"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # here where you will use the models that are saved by tf\n",
    "  # for this code it used EfficientNetB0 and removing the top to replace with a specified variables for our use case\n",
    "  model_parts = tf.keras.applications.EfficientNetB0(include_top = False)\n",
    "\n",
    "  # it sets the model to freeze mode which means that the values inside the nodes wont change but will still learn accordingly to how they are trained\n",
    "  model_parts.trainable = False\n",
    "\n",
    "  # this will replace the remove early on the use of finished model that states like this:\n",
    "  # it is Input that will set the images(shape) into 224x224 with RGB(3) and has a name of layer (name) input_layer\n",
    "  input = Input(shape = (500, 500, 3), name = \"input_layer\")\n",
    "\n",
    "  # here you will connect the input_layer and the model\n",
    "  x = model_parts(input)\n",
    "\n",
    "  # here you will now add some layer below / at the end of the process a layer and read like this:\n",
    "  # adding GlobalAveragePooling2D with a name (name) of GAP2D_layer below the model (x) and stored in x\n",
    "  x = GlobalAveragePooling2D(name = \"GAP2D_layer\")(x)\n",
    "\n",
    "  # adding the final layer which decides which is which and read like this:\n",
    "  # adding Dense with 3 class, with activation of softmax that is named output_layer below x and stored in output\n",
    "  output = Dense(3, activation = \"softmax\", name = \"output_layer\")(x)\n",
    "\n",
    "  # now building the model\n",
    "  # Model has head of input and ends with output that is named \"EffNet0_FE\"\n",
    "    ## you can change the name on how you want\n",
    "  model_test = Model(input, output, name = \"Final_Model\")\n",
    "\n",
    "  # compiling the model saying that it is categorical by categorical_crossentropy, has Adam as its optimizer, and will also add information about categoricalaccuracy and precision\n",
    "  model_test.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = Adam(0.0001),\n",
    "    metrics = [\"CategoricalAccuracy\", \"Precision\"]\n",
    "  )\n",
    "\n",
    "  # saving the data of the model into model_test_h for history data while fitting (fit)\n",
    "  # inside the fit you need train_data(which stores the directory of training sets prepared at the top)\n",
    "  # - epochs which says how many times do i need to train the model\n",
    "  # >> note the other are just extras\n",
    "  # validation_data which need the test_data(which stores the directory of test sets prepared at the top)\n",
    "  # - to validate it while being trained\n",
    "  # - callbacks which 1. checkpoint function which is also set at the top, will do checkpointing\n",
    "  # 2. tensorboard_callback to create a graph of data in ./log/EffNet0 with the name of Model 2\n",
    "  # >> note you should always create different folder for different models\n",
    "  # >> note or you should always rename the name when testing with same model but different configuration\n",
    "  # >> note: also to be aware if you can see the validation_data has the test_data which smells fishy you correct that is improper\n",
    "  # - because we should have validation dataset to use here and use the test_data for the testing.\n",
    "  # pero dahil kulang pa tayo data yun muna pansamantala\n",
    "  model_test_h = model_test.fit(train_data,\n",
    "                          epochs = 20,\n",
    "                          validation_data = test_data,\n",
    "                          callbacks = [checkpoint,\n",
    "                                      _helper.callbacks.tensorboard_callback(\"./log/finalUlit\",\n",
    "                                                                              \"Final_model\")])\n",
    "  _helper.notifications.model_callback_notification()\n",
    "except Exception as e:\n",
    "  print(f\"Error: {e}\")\n",
    "  _helper.notifications.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_files/final/checkpoint/final.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d794ee5f90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.load_weights(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 1s/step - loss: 0.8438 - categorical_accuracy: 0.5889 - precision: 0.6265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8438289165496826, 0.5888888835906982, 0.6265060305595398]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is used to evaluate din\n",
    "model_test.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved to ./saved_files/h5/Final_1/Final_1_2022_10_31 - 18.h5 and ./saved_files/h5/Final_1/Final_1_diagram.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # this is used to save the model and/or history\n",
    "  _helper.save_load.save(model = model_test,\n",
    "                        path = \"./saved_files/h5/finalUlit\",\n",
    "                        name = \"Final_1\")\n",
    "except Exception as e:\n",
    "  print(f\"Error {e}\")\n",
    "  _helper.notifications.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight normalization_1/count with shape () and dtype int64 was auto converted to the type int32\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "  # this is used to save the model to JS\n",
    "  tfjs.converters.save_keras_model(model_test, \"./saved_files/JS/finalUlit/\")\n",
    "except Exception as e:\n",
    "  print(f\"Error {e}\")\n",
    "  _helper.notifications.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('Sparta': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a325f8354c59d5b8e3e6c378b83e7027e07cdd2e48658b2bcc43f133e70682cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
